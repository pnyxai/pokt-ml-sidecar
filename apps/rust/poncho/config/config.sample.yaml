log_level: "debug"
server:
  host: "127.0.0.1"
  port: 8080
vllm_backend:
  host: "http://127.0.0.1"
  port: 8000
  model_name_override: "meta-llama/Llama-3.1-8B-Instruct"
  allow_logprobs: false
  crop_max_tokens: true
routing:
  timeout_seconds: 600
  max_payload_size_mb: 10
model_config_data:
    model_public_name : "pocket_network"
    max_position_embeddings : 4096